{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:41:06.458108Z",
     "start_time": "2023-05-31T15:41:06.453325Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/tiiktak/fashion-mnist-with-alexnet-in-pytorch-92-accuracy\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training batches of our network\n",
    "EPOCHS = 10\n",
    "# size of each batch\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "DEVICE = (\"mps\")  # if torch.cuda.is_available() else \"cpu\")\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(torch.__version__)\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data\n",
    "There are two ways to laod the Fashion-MNIST dataset:\n",
    "\n",
    "use the dataset given in the datasets.FashionMNIST\n",
    "use raw data\n",
    "Here I use the data on Kaggle, so we need to build the dataset\n",
    "\n",
    "Firstly, import the '.csv' files with pd.read_csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('./fashionmnist/fashion-mnist_train.csv')\n",
    "test_csv = pd.read_csv('./fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "print(train_csv.shape)\n",
    "print(test_csv.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_csv.info())\n",
    "print(train_csv.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset\n",
    "To build our own dataset, need to create a class that inherits from the Dataset. Besides, function get_item() & len() must be defined at least\n",
    "\n",
    "get_item() return the specified image and its label\n",
    "len() return the number of dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "\n",
    "        label, image = [], []\n",
    "\n",
    "        for i in self.fashion_MNIST:\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28).astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        image = self.images[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            # transfrom the numpy array to PIL image before the transform function\n",
    "            pil_image = Image.fromarray(np.uint8(image))\n",
    "            image = self.transform(pil_image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:39:40.569541Z",
     "start_time": "2023-05-31T15:39:40.561560Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform\n",
    "Because the input size of AlexNet is  227∗227\n",
    " , and the image size of Fashion-MNIST is  28∗28\n",
    " , so we need to resize the image in the transform function\n",
    "\n",
    "Since transforms.Resize() only works to the PIL Image,we transform the numpy array to PIL Image above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "AlexTransform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:39:45.353227Z",
     "start_time": "2023-05-31T15:39:45.349123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    FashionDataset(train_csv, transform=AlexTransform),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    FashionDataset(test_csv, transform=AlexTransform),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:39:50.110636Z",
     "start_time": "2023-05-31T15:39:49.914143Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # helper function to show an image\n",
    "# def matplotlib_imshow(img):\n",
    "#     img = img.mean(dim=0)\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(npimg, cmap=\"Greys\")\n",
    "#\n",
    "# # get some random training images\n",
    "# dataiter = iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "#\n",
    "# # creat grid of images\n",
    "# img_grid = torchvision.utils.make_grid(images[0])\n",
    "#\n",
    "# # show images & labels\n",
    "# matplotlib_imshow(img_grid)\n",
    "# print(class_names[labels[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "try:\n",
    "    images, labels = next(dataiter)\n",
    "except StopIteration:\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images[0])\n",
    "\n",
    "# show images & labels\n",
    "# matplotlib.imshow(img_grid)\n",
    "print(class_names[labels[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:41:16.762700Z",
     "start_time": "2023-05-31T15:41:16.588021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class fasion_mnist_alexnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.dropout(out, 0.5)\n",
    "        out = self.fc3(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:41:19.664637Z",
     "start_time": "2023-05-31T15:41:19.658608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = fasion_mnist_alexnet().to(DEVICE)\n",
    "criterion = F.nll_loss\n",
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:41:24.252575Z",
     "start_time": "2023-05-31T15:41:23.731494Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target.type(torch.LongTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % 30 == 0:\n",
    "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:42:03.714829Z",
     "start_time": "2023-05-31T15:42:03.708396Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)  # loss之和除以data数量 -> mean\n",
    "        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "        print('='*50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T15:42:05.180558Z",
     "start_time": "2023-05-31T15:42:05.174614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.load('save/mnist_Alex.pt')\n",
    "EPOCHS = 1\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)\n",
    "torch.save(model, 'save/mnist_Alex.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# torch.save(model, 'save/mnist_Alex.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T22:08:42.725711Z",
     "start_time": "2023-05-31T22:08:42.202962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = torch.load('save/mnist_cnn_Alex.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
