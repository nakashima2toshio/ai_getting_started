{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "VGG16 ant&bee"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "data_dir = \"./data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "target_path = \"./data/hymenoptera_data.zip\"\n",
    "if not os.path.exists(target_path):\n",
    "    urllib.request.urlretrieve(url, target_path)\n",
    "\n",
    "zip = zipfile.ZipFile(\"./data/hymenoptera_data.zip\")\n",
    "zip.extractall(\"./data\")  # ZIPを解凍\n",
    "zip.close()  # ZIPファイルをクローズ\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T04:16:27.418547Z",
     "start_time": "2023-06-11T04:16:25.740884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "import torch\n",
    "\n",
    "'''2. 前処理クラスの定義'''\n",
    "'''画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
    "Attributes:\n",
    "  data_transform(dic):\n",
    "    train: 訓練用のトランスフォーマーオブジェクト\n",
    "    val  : 検証用のトランスフォーマーオブジェクト\n",
    "'''\n",
    "'''トランスフォーマーオブジェクトを生成する。\n",
    "\n",
    "Parameters:\n",
    "resize(int): リサイズ先の画像の大きさ\n",
    "mean(tuple): (R, G, B)各色チャネルの平均値\n",
    "std        : (R, G, B)各色チャネルの標準偏差\n",
    "'''\n",
    "class ImageTransform():\n",
    "\n",
    "    def __init__(self, resize, mean, std):\n",
    "        # dicに訓練用、検証用のトランスフォーマーを生成して格納\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                # ランダムにトリミングする\n",
    "                transforms.RandomResizedCrop(\n",
    "                    resize, # トリミング後の出力サイズ\n",
    "                    scale=(0.5, 1.0)),  # スケールの変動幅\n",
    "                transforms.RandomHorizontalFlip(p = 0.5),  # 0.5の確率で左右反転\n",
    "                transforms.RandomRotation(15),  # 15度の範囲でランダムに回転\n",
    "                transforms.ToTensor(),          # Tensorオブジェクトに変換\n",
    "                transforms.Normalize(mean, std) # 標準化\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(resize),      # リサイズ\n",
    "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeでトリミング\n",
    "                transforms.ToTensor(),          # テンソルに変換\n",
    "                transforms.Normalize(mean, std) # 標準化\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        '''オブジェクト名でコールバックされる\n",
    "        Parameters:\n",
    "          img: 画像\n",
    "          phase(str): 'train'または'val' 前処理のモード\n",
    "        '''\n",
    "        return self.data_transform[phase](img) # phaseはdictのキー"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T04:21:13.733965Z",
     "start_time": "2023-06-11T04:21:12.874846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4.  アリとハチの画像のファイルパスをリストにする\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import os.path as osp\n",
    "import glob\n",
    "import pprint\n",
    "\n",
    "def make_datapath_list(phase=\"train\"):\n",
    "    '''\n",
    "    データのファイルパスを格納したリストを作成する。\n",
    "    Parameters:\n",
    "      phase(str): 'train'または'val'\n",
    "\n",
    "    Returns:\n",
    "      path_list(list): 画像データのパスを格納したリスト\n",
    "    '''\n",
    "    # 画像ファイルのルートディレクトリ\n",
    "    rootpath = \"./data/hymenoptera_data/\"\n",
    "    # 画像ファイルパスのフォーマットを作成\n",
    "    # rootpath +\n",
    "    #   train/ants/*.jpg\n",
    "    #   train/bees/*.jpg\n",
    "    #   val/ants/*.jpg\n",
    "    #   val/bees/*.jpg\n",
    "    target_path = osp.join(rootpath + phase + '/**/*.jpg')\n",
    "    # ファイルパスを格納するリスト\n",
    "    path_list = []  # ここに格納する\n",
    "\n",
    "    # glob()でファイルパスを取得してリストに追加\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "\n",
    "    return path_list\n",
    "\n",
    "# ファイルパスのリストを生成\n",
    "train_list = make_datapath_list(phase=\"train\")\n",
    "val_list = make_datapath_list(phase=\"val\")\n",
    "\n",
    "# 訓練データのファイルパスの前後5要素ずつ出力\n",
    "print('train')\n",
    "pprint.pprint(train_list[:5])\n",
    "pprint.pprint(train_list[-6:-1])\n",
    "# 検証データのファイルパスの前後5要素ずつ出力\n",
    "print('val')\n",
    "pprint.pprint(val_list[:5])\n",
    "pprint.pprint(val_list[-6:-1])\n",
    "# 画像の前処理と処理済み画像の表示\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(Image.open(train_list[0]))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 画像の前処理と処理済み画像の表示\n",
    "# 5. アリとハチの画像のデータセットを作成するクラス\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "class MakeDataset(data.Dataset):\n",
    "    '''\n",
    "    アリとハチの画像のDatasetクラス\n",
    "    PyTorchのDatasetクラスを継承\n",
    "\n",
    "    Attributes:\n",
    "      file_list(list): 画像のパスを格納したリスト\n",
    "      transform(object): 前処理クラスのインスタンス\n",
    "      phase(str): 'train'または'val'\n",
    "    Returns:\n",
    "      img_transformed: 前処理後の画像データ\n",
    "      label(int): 正解ラベル\n",
    "    '''\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        '''インスタンス変数の初期化\n",
    "        '''\n",
    "        self.file_list = file_list  # ファイルパスのリスト\n",
    "        self.transform = transform  # 前処理クラスのインスタンス\n",
    "        self.phase = phase          # 'train'または'val'\n",
    "\n",
    "    def __len__(self):\n",
    "        '''len(obj)で実行されたときにコールされる関数\n",
    "        画像の枚数を返す'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Datasetクラスの__getitem__()をオーバーライド\n",
    "           obj[i]のようにインデックスで指定されたときにコールバックされる\n",
    "\n",
    "           Parameters:\n",
    "             index(int): データのインデックス\n",
    "           Returns:\n",
    "\n",
    "          前処理をした画像のTensor形式のデータとラベルを取得\n",
    "        '''\n",
    "\n",
    "        # ファイルパスのリストからindex番目の画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        # ファイルを開く -> (高さ, 幅, RGB)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # 画像を前処理  -> torch.Size([3, 224, 224])\n",
    "        img_transformed = self.transform(\n",
    "            img, self.phase)\n",
    "\n",
    "        # 正解ラベルをファイル名から切り出す\n",
    "        if self.phase == 'train':\n",
    "            # 訓練データはファイルパスの31文字から34文字が'ants'または'bees'\n",
    "            label = img_path[30:34]\n",
    "        elif self.phase == 'val':\n",
    "            # 検証データはファイルパスの29文字から32文字が'ants'または'bees'\n",
    "            label = img_path[28:32]\n",
    "\n",
    "        # 正解ラベルの文字列を数値に変更する\n",
    "        if label == 'ants':\n",
    "            label = 0 # アリは0\n",
    "        elif label == 'bees':\n",
    "            label = 1 # ハチは1\n",
    "\n",
    "        return img_transformed, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T05:10:26.784109Z",
     "start_time": "2023-06-11T05:10:26.769764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 6. データローダーの生成\n",
    "\n",
    "import torch\n",
    "\n",
    "# ミニバッチのサイズを指定\n",
    "batch_size = 32\n",
    "\n",
    "# 画像のサイズ\n",
    "SIZE = 224\n",
    "# 画像の平均値 (RGB)\n",
    "MEAN = (0.485, 0.456, 0.406)\n",
    "# 画像の標準偏差 (RGB)\n",
    "STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "# 画像のサイズ、平均値、標準偏差の定数値\n",
    "size, mean, std = SIZE, MEAN, STD\n",
    "\n",
    "# MakeDatasetで前処理後の訓練データと正解ラベルを取得\n",
    "train_dataset = MakeDataset(\n",
    "    file_list=train_list, # 訓練データのファイルパス\n",
    "    transform=ImageTransform(size, mean, std), # 前処理後のデータ\n",
    "    phase='train')\n",
    "# MakeDatasetで前処理後の検証データと正解ラベルを取得\n",
    "val_dataset = MakeDataset(\n",
    "    file_list=val_list, # 検証データのファイルパス\n",
    "    transform=ImageTransform(size, mean, std), # 前処理後のデータ\n",
    "    phase='val')\n",
    "\n",
    "# 訓練用のデータローダー:(バッチサイズ, 3, 224, 224)を生成\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# 検証用のデータローダー:(バッチサイズ, 3, 224, 224)を生成\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# データローダーをdictにまとめる\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T05:47:06.788617Z",
     "start_time": "2023-06-11T05:47:06.782138Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 7. 学習済みのVGG16モデルをロード\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# ImageNetで事前トレーニングされたVGG16モデルを取得\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# VGG16の出力層のユニット数を2にする\n",
    "model.classifier[6] = nn.Linear(\n",
    "    in_features=4096, # 入力サイズはデフォルトの4096\n",
    "    out_features=2)   # 出力はデフォルトの1000から2に変更\n",
    "\n",
    "# 使用可能なデバイス(CPUまたはGPU）を取得する\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# 8. VGG16で学習可能にする層を設定\n",
    "\n",
    "# 転移学習で学習させるパラメータを、変数params_to_updateに格納する\n",
    "params_to_update = []\n",
    "\n",
    "# 出力層の重みとバイアスを更新可として登録\n",
    "update_param_names = ['classifier.6.weight', 'classifier.6.bias']\n",
    "\n",
    "# 出力層以外は勾配計算をなくし、変化しないように設定\n",
    "for name, param in model.named_parameters():\n",
    "    if name in update_param_names:\n",
    "        param.requires_grad = True # 勾配計算を行う\n",
    "        params_to_update.append(param) # パラメーター値を更新\n",
    "        print(name) # 更新するパラメーター名を出力\n",
    "    else:\n",
    "        param.requires_grad = False # 出力層以外は勾配計算なし"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T05:49:09.883585Z",
     "start_time": "2023-06-11T05:49:09.868159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 9. 損失関数とオプティマイザーを生成\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# オプティマイザー\n",
    "optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T05:49:26.354580Z",
     "start_time": "2023-06-11T05:49:26.341068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 10.  学習を行う関数の定義\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    '''モデルを使用して学習を行う\n",
    "\n",
    "    Parameters:\n",
    "      model: モデルのオブジェクト\n",
    "      dataloaders(dict): 訓練、検証のデータローダー\n",
    "      criterion: 損失関数\n",
    "      optimizer: オプティマイザー\n",
    "      num_epochs: エポック数\n",
    "    '''\n",
    "    # epochの数だけ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # 学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # モデルを訓練モードにする\n",
    "            else:\n",
    "                model.eval()   # モデルを検証モードにする\n",
    "\n",
    "            epoch_loss = 0.0    # 1エポックあたりの損失の和\n",
    "            epoch_corrects = 0  # 1エポックあたりの精度の和\n",
    "\n",
    "            # 未学習時の検証性能を確かめるため、epoch=0の学習は行わない\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            # 1ステップにおける訓練用ミニバッチを使用した学習\n",
    "            # tqdmでプログレスバーを表示する\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                # torch.Tensorオブジェクトにデバイスを割り当てる\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # オプティマイザーを初期化\n",
    "                optimizer.zero_grad()\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs) # モデルの出力を取得\n",
    "                    # 出力と正解ラベルの誤差から損失を取得\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # 出力された要素数2のテンソルの最大値を取得\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "                    # 訓練モードではバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() # 逆伝播の処理(自動微分による勾配計算)\n",
    "                        optimizer.step() # 勾配降下法でバイアス、重みを更新\n",
    "\n",
    "                    # ステップごとの損失を加算、inputs.size(0)->32\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    # ステップごとの精度を加算\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # エポックごとの損失と精度を表示\n",
    "            epoch_loss = epoch_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "                ) / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # 出力\n",
    "            print('{} - loss: {:.4f} - acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T05:50:05.636329Z",
     "start_time": "2023-06-11T05:50:05.628128Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - loss: 0.7049 - acc: 0.5686\n",
      "Epoch 2/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:20<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - loss: 0.5646 - acc: 0.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - loss: 0.2182 - acc: 0.9477\n",
      "Epoch 3/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:19<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - loss: 0.2394 - acc: 0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - loss: 0.1377 - acc: 0.9608\n",
      "CPU times: user 5min 54s, sys: 37.2 s, total: 6min 31s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 11.  学習・検証を実行する\n",
    "num_epochs=3\n",
    "train_model(model, dataloaders, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "save"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T05:51:46.416198Z",
     "start_time": "2023-06-11T05:50:27.131815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
